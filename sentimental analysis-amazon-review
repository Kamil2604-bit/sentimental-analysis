import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# Download necessary NLTK data (only needed once)
nltk.download('vader_lexicon')
nltk.download('stopwords')
# Download the 'punkt_tab' resource
nltk.download('punkt_tab') # This line is added to fix the error

# Sample data (replace with your actual Amazon review data)
reviews = [
    ("This guitar is amazing!  The sound is incredible.", "positive"),
    ("I hated this keyboard.  The keys felt cheap.", "negative"),
    ("The drums are okay, but could be better.", "neutral"),
    ("This violin is a masterpiece!  Highly recommended.", "positive"),
    ("Very disappointed with the quality of this ukulele.", "negative"),
    ("Decent amp for the price.", "positive"),
    ("Awful sound, would not recommend.", "negative"),
    ("It's alright, nothing special.", "neutral"),
    ("Excellent value for money!", "positive"),
    ("Complete waste of money.", "negative")
]

# Separate reviews and labels
review_texts = [review[0] for review in reviews]
labels = [review[1] for review in reviews]

# Preprocessing: Lowercase and remove stop words
stop_words = set(stopwords.words('english'))
processed_reviews = []
for review in review_texts:
    words = nltk.word_tokenize(review.lower())
    words = [w for w in words if not w.isalnum() or w not in stop_words]
    processed_reviews.append(" ".join(words))


# Lexicon-based sentiment analysis (VADER)
analyzer = SentimentIntensityAnalyzer()
vader_scores = []
for review in processed_reviews:
    scores = analyzer.polarity_scores(review)
    vader_scores.append(scores['compound'])

# Naive Bayes classification
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(processed_reviews)
y = labels

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = MultinomialNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Evaluation
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))


# Example of predicting sentiment on a new review
new_review = "This piano is fantastic; I love the sound and feel!"
processed_new_review = " ".join([w for w in nltk.word_tokenize(new_review.lower()) if w not in stop_words])
new_review_vec = vectorizer.transform([processed_new_review])
prediction = model.predict(new_review_vec)[0]
print(f"Sentiment of new review: {prediction}")
